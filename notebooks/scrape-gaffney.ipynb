{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the import keyword to import pandas, requests, and bs4 modules\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the NY WARN notice url to a variable\n",
    "url = \"https://labor.ny.gov/app/warn/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define headers\n",
    "headers = {'accept-encoding': 'deflate'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a get request to the url using the requests library and assign the response to a variable called 'response'\n",
    "response = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out status code of response to confirm that your request worked\n",
    "# response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the response text using Beautiful Soup's html parser and assign output to a variable called 'soup'\n",
    "# response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape the first table on the page and assign it to a variable called 'table'\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab all rows from the table and assign to a variable called 'rows'\n",
    "table = soup.find(\"table\")\n",
    "# table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the number of rows â€” this is how many WARN notices there were in 2020\n",
    "rows = soup.find_all(\"tr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1285"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an array called 'results'\n",
    "results = []\n",
    "# loop through the rows using a for loop. each row here is a company\n",
    "for row in rows:\n",
    "    # grab the anchor tag (the link tag) in the row and then grab the href attribute from the tag\n",
    "    a = row.find(\"a\")['href']\n",
    "    \n",
    "    # concatenate the root url from above with this href attribute and assign to a variable called 'company_url'\n",
    "    company_url = f'{url}{a}'\n",
    "    \n",
    "    # make a get request to the company url assign the response to a variable called 'company_response'\n",
    "    company_response = requests.get(company_url, headers=headers)\n",
    "    \n",
    "    # parse the response text and assign output to a variable called 'company_soup'\n",
    "    company_soup = BeautifulSoup(company_response.text, 'html.parser')\n",
    "\n",
    "    # grab the first table on the page\n",
    "    company_table = company_soup.find(\"table\")\n",
    "\n",
    "    # unwrap all of the spans\n",
    "    \n",
    "    # loop through all of the p tags\n",
    "    paragraphs = company_table.find_all(\"p\")\n",
    "    for p in paragraphs:\n",
    "        # grab all of the values we want\n",
    "        text = p.get_text('\\n')\n",
    "        if 'Date of Notice:' in text:\n",
    "            notice_date = text.split(\":\")[1].strip().split('\\n')[0].strip().replace(',', '').replace(';', '')\n",
    "            #print(notice_date)\n",
    "        elif 'Reason Stated for Filing:' in text:\n",
    "            reason = text.split(\":\")[1].strip()\n",
    "            #print(reason)\n",
    "        elif 'Company:' in text:\n",
    "            split_company = text.split(\"\\n\")\n",
    "            #print(split_company)\n",
    "            company = split_company[1].strip()\n",
    "            address = ''.join(split_company[2:])\n",
    "#             print(company)\n",
    "#             print(address)\n",
    "        elif 'County:' in text:\n",
    "            county = f'{text.split(\":\")[1].strip().split(\"|\")[0].strip()} County'\n",
    "            #print(county)\n",
    "        elif 'Phone:' in text:\n",
    "            phone = text.split(\":\")[1].strip()\n",
    "            #print(phone)\n",
    "        elif 'Business Type:' in text:\n",
    "            business_type = text.split(\":\")[1].strip().replace('Restaurants', 'Restaurant')\n",
    "            #print(business_type)\n",
    "        elif 'Number Affected:' in text:\n",
    "            if '-----' in text:\n",
    "                affected = ''\n",
    "            else:\n",
    "                affected = text.split(\":\")[1].strip().split(\" \")[0].strip().split('\\n')[0].strip()\n",
    "            #print(affected)\n",
    "        elif 'Total Employees:' in text:\n",
    "            if '-----' in text:\n",
    "                total_employees = ''\n",
    "            else:\n",
    "                total_employees = text.split(\":\")[1].strip().split(\" \")[0].strip().replace(',', '')\n",
    "                #print(total_employees)\n",
    "        elif 'Layoff Date:' in text:\n",
    "            #print(text)\n",
    "            layoff_date = text.split(\":\")[1].strip().split(\" \")[0].strip().split(\" \")[0].strip()\n",
    "            #print(layoff_date)\n",
    "        elif ('Reason for Dislocation:' in text):\n",
    "            dislocation = text.split(\":\")[1].strip()\n",
    "            #print(dislocation)\n",
    "        elif ('Union:' in text):\n",
    "            union = text.split(\":\")[1].strip()\n",
    "            #print(union)\n",
    "        elif ('Classification:' in text):\n",
    "            classification = text.split(\":\")[1].strip()\n",
    "            #print(classification)\n",
    "            \n",
    "    # store values in a result object\n",
    "    result = {\n",
    "        'notice_date': notice_date,\n",
    "        'reason': reason,\n",
    "        'company': company,\n",
    "        'address': address,\n",
    "        'county': county,\n",
    "        'phone': phone,\n",
    "        'business_type': business_type,\n",
    "        'affected': affected,\n",
    "        'total_employees': total_employees,\n",
    "        'layoff_date': layoff_date,\n",
    "        'dislocation': dislocation,\n",
    "        'union': union,\n",
    "        'classification': classification\n",
    "     }\n",
    "    \n",
    "    # append result object to results\n",
    "    results.append(result)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap results in a dataframe\n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5/15/2020', '3/15/2020', '5/1/2020', 'Layoffs', '3/23/2020',\n",
       "       '4/30/2020', '5/5/2020', 'These', '5/8/2020', '5/2/2020',\n",
       "       '3/30/2020', '3/14/2020', '5/18/2020', '3/27/2020', '5/6/2020',\n",
       "       '3/18/2020', '3/17/2020', '3/12/2020', '4/1/2020', 'March',\n",
       "       '3/16/2020', 'The', '3/19/2020', '5/29/2020', '6/1/2020',\n",
       "       '4/24/2020', '4/16/2020', '3/20/2020', '4/3/2020', '6/30/2020',\n",
       "       '4/23/2020', '4/4/2020', '4/8/2020', '4/22/2020', '3/24/2020',\n",
       "       '4/13/2020', '4/10/2020', 'Furloughs', '3/22/2020', 'Separation',\n",
       "       '3/29/2020', '3/25/2020', 'Separations', '23', '7/30/2020',\n",
       "       '4/25/2020', '7/19/2020', '6/19/2020', '7/3/2020', '4/20/2020',\n",
       "       '3/31/2020', '4/14/2020', '3/28/2020', '72', '51', '86', '88',\n",
       "       '37', 'Nine', '4/6/2020', '(21)', '(27)', '30', '18', '14',\n",
       "       'Seven', '4/2/2020', '3/21/2020', '356', '34', '330', '69', '52',\n",
       "       '87', '81', '-----', '4/7/2020', '48', '3/26/2020', '3/10/2020',\n",
       "       '4/12/2020', '362', '3/13/2020', '4/5/2020', '3/19/2020,',\n",
       "       '7/12/2020', '4/11/2020', '6/26/2020', '4/1/2020,', '7/1/2020',\n",
       "       '287', 'A', '146', '3/6/2020', 'May', '6/21/2020', '6/24/2020',\n",
       "       '2/23/2020', '3/11/2020', 'Close', '', '6/12/2020', 'June',\n",
       "       'First', '6/17/2020', 'To', '7/31/2020', '6/3/2020', '6/14/2020',\n",
       "       '5/31/2020', 'December', 'Employee', 'Employment', '2/29/2020',\n",
       "       '5/22/2020', 'April', 'Separtions', 'Employees', '4/27/2020',\n",
       "       \"Macy's\", 'Beginning', '1/12/2020'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows = 1237\n",
    "df['layoff_date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output dataframe to a csv\n",
    "df.to_csv('../data/warn-gaffney.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
